{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572d306-7bfc-4ec0-b84c-0c3f666b2dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7c1c22-5917-49c3-8ec4-b031bd5bda84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tft/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 170 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x153a049a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "Predicted price for NUBL: 764.79 for date: 2025-02-07\n",
      "Actual price: 690.00\n",
      "Accuracy: 9.78%\n",
      "Threshold region: 726.55 to 803.02\n",
      "Prediction is within threshold: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the threshold region (e.g., ±2% around the predicted price)\n",
    "THRESHOLD_PERCENTAGE = 5\n",
    "\n",
    "def load_and_preprocess_data(file_path, scaler_path, window_size=5):\n",
    "    df_stock = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert 'Date' column to datetime\n",
    "    df_stock['Date'] = pd.to_datetime(df_stock['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Remove '%' and convert 'Percent Change' to float, handling errors\n",
    "    df_stock['Percent Change'] = df_stock['Percent Change'].str.replace('%', '').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remove commas from 'Volume' and convert to float\n",
    "    df_stock['Volume'] = df_stock['Volume'].astype(str).str.replace(',', '').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Create additional features\n",
    "    df_stock['day_of_week'] = df_stock['Date'].dt.dayofweek\n",
    "    df_stock['month'] = df_stock['Date'].dt.month\n",
    "\n",
    "    # Load scaler\n",
    "    if not os.path.exists(scaler_path):\n",
    "        raise FileNotFoundError(f\"Scaler file {scaler_path} not found.\")\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # Select features and normalize\n",
    "    features = ['Close', 'day_of_week', 'month']\n",
    "    df_stock[features] = scaler.transform(df_stock[features])\n",
    "\n",
    "    # Prepare sequence for prediction\n",
    "    X = df_stock[features].iloc[-window_size:].values\n",
    "    return np.expand_dims(X, axis=0)  # Shape: (1, window_size, features)\n",
    "\n",
    "def predict_stock_price(model_path, scaler_path, file_path, threshold_percentage=THRESHOLD_PERCENTAGE):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file {model_path} not found.\")\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    X = load_and_preprocess_data(file_path, scaler_path)\n",
    "\n",
    "    # Make prediction (normalized scale)\n",
    "    predicted_price_norm = model.predict(X)[0][0]\n",
    "\n",
    "    # Load scaler and apply inverse transformation\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Only transform the \"Close\" value (we assume it was first in the feature list)\n",
    "    predicted_price_original = scaler.inverse_transform(\n",
    "        np.array([[predicted_price_norm, 0, 0]])  # Set other features to 0\n",
    "    )[0][0]  # Extract only the Close price\n",
    "\n",
    "    # Get last known actual price\n",
    "    df_stock = pd.read_csv(file_path)\n",
    "    actual_price = df_stock['Close'].iloc[-1]  # Assuming 'Close' is the last column\n",
    "\n",
    "    # Calculate threshold region (±2% around predicted price)\n",
    "    lower_bound = predicted_price_original * (1 - threshold_percentage / 100)\n",
    "    upper_bound = predicted_price_original * (1 + threshold_percentage / 100)\n",
    "\n",
    "    # **Enhanced Dynamic Threshold:**\n",
    "    # You can also adjust the threshold region dynamically based on the recent price fluctuation\n",
    "    # For example, you can check the recent percentage change to expand the range.\n",
    "    recent_price_change = (df_stock['Close'].iloc[-1] - df_stock['Close'].iloc[-2]) / df_stock['Close'].iloc[-2] * 100\n",
    "    dynamic_threshold_percentage = threshold_percentage + abs(recent_price_change) / 2  # Adding a factor of recent fluctuation\n",
    "    lower_bound = actual_price * (1 - threshold_percentage / 100)\n",
    "    upper_bound = actual_price * (1 + threshold_percentage / 100)\n",
    "\n",
    "    # Check if actual price is within the threshold region\n",
    "    is_accurate = lower_bound <= predicted_price_original <= upper_bound\n",
    "    accuracy = (actual_price - predicted_price_original) / predicted_price_original * 100  # Accuracy in percentage\n",
    "    if accuracy<0:\n",
    "        accuracy=accuracy*-1\n",
    "\n",
    "    last_date = df_stock['Date'].iloc[-1]  # Get the last date from the 'Date' column\n",
    "    return predicted_price_original, actual_price, is_accurate, accuracy, last_date\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = '../NULB/'  # Update to your actual data path\n",
    "\n",
    "    for file_name in os.listdir(data_directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            stock_name = os.path.splitext(file_name)[0]\n",
    "            file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "            model_path = os.path.join(data_directory, f\"{stock_name}_tft_model.keras\")\n",
    "            scaler_path = os.path.join(data_directory, f\"{stock_name}_scaler.pkl\")\n",
    "\n",
    "            try:\n",
    "                predicted_price, actual_price, is_accurate, accuracy, last_column_date = predict_stock_price(\n",
    "                    model_path, scaler_path, file_path\n",
    "                )\n",
    "\n",
    "                date_obj = datetime.strptime(last_column_date, '%Y-%m-%d')\n",
    "                \n",
    "                # Add one day\n",
    "                new_date_obj = date_obj + timedelta(days=1)\n",
    "                \n",
    "                # Convert back to string if needed\n",
    "                new_date_str = new_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "                print(f\"Predicted price for {stock_name}: {predicted_price:.2f} for date: {new_date_str}\")\n",
    "                print(f\"Actual price: {actual_price:.2f}\")\n",
    "                print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "                print(f\"Threshold region: {predicted_price * (1 - THRESHOLD_PERCENTAGE / 100):.2f} to {predicted_price * (1 + THRESHOLD_PERCENTAGE / 100):.2f}\")\n",
    "                print(f\"Prediction is within threshold: {is_accurate}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {stock_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af9e8f-2aa5-4ec1-beba-fec9104ec477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
