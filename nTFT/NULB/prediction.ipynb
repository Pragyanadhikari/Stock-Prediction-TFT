{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572d306-7bfc-4ec0-b84c-0c3f666b2dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7c1c22-5917-49c3-8ec4-b031bd5bda84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "Predicted price for NUBL: 730.81 for date: 2025-02-07\n",
      "Actual price: 690.00\n",
      "Accuracy: 5.58%\n",
      "Threshold region: 694.27 to 767.35\n",
      "Prediction is within threshold: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from datetime import datetime, timedelta\n",
    "import ta\n",
    "\n",
    "# Define the threshold region (e.g., ±2% around the predicted price)\n",
    "THRESHOLD_PERCENTAGE = 5\n",
    "# Function for feature selection using Pearson correlation\n",
    "def select_features(X, threshold=0.8):\n",
    "    # Remove non-numeric columns (if any) for correlation computation\n",
    "    X_numeric = X.select_dtypes(include=[np.number])\n",
    "    \n",
    "    col_corr = set()\n",
    "    corr_matrix = X_numeric.corr()\n",
    "\n",
    "    # Check for highly correlated features and add them to the set to be dropped\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return X.drop(columns=col_corr)\n",
    "def load_and_preprocess_data(file_path, scaler_path, window_size=5):\n",
    "    df_stock = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert 'Date' column to datetime\n",
    "    df_stock['Date'] = pd.to_datetime(df_stock['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Remove '%' and convert 'Percent Change' to float, handling errors\n",
    "    df_stock['Percent Change'] = df_stock['Percent Change'].str.replace('%', '').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remove commas from 'Volume' and convert to float\n",
    "    df_stock['Volume'] = df_stock['Volume'].astype(str).str.replace(',', '').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Create additional features\n",
    "    df_stock['day_of_week'] = df_stock['Date'].dt.dayofweek\n",
    "    df_stock['month'] = df_stock['Date'].dt.month\n",
    "    # Use 'Ltp' instead of 'Close' if necessary\n",
    "    close_col = 'Close'\n",
    "    high_col = 'High'\n",
    "    low_col = 'Low'\n",
    "    volume_col = 'Volume'\n",
    "\n",
    "    # Technical indicators\n",
    "    df_stock['Returns'] = df_stock[close_col].pct_change().fillna(0)\n",
    "    df_stock['MACD'] = ta.trend.MACD(df_stock[close_col]).macd().fillna(0)\n",
    "    df_stock['Signal'] = ta.trend.MACD(df_stock[close_col]).macd_signal().fillna(0)\n",
    "    df_stock['RSI'] = ta.momentum.RSIIndicator(df_stock[close_col]).rsi().fillna(50)\n",
    "    df_stock['SMA_20'] = df_stock[close_col].rolling(window=20, min_periods=1).mean()\n",
    "    df_stock['SMA_50'] = df_stock[close_col].rolling(window=50, min_periods=1).mean()\n",
    "    df_stock['EMA_20'] = ta.trend.EMAIndicator(df_stock[close_col], window=20).ema_indicator().fillna(0)\n",
    "\n",
    "    # Volatility measures\n",
    "    df_stock['Volatility'] = df_stock['Returns'].rolling(window=20).std().fillna(0)\n",
    "    df_stock['ATR'] = ta.volatility.AverageTrueRange(df_stock[high_col], df_stock[low_col], df_stock[close_col]).average_true_range().fillna(0)\n",
    "\n",
    "    # Volume-based indicators\n",
    "    df_stock['Volume_SMA'] = df_stock[volume_col].rolling(window=20).mean().fillna(0)\n",
    "    df_stock['Volume_Ratio'] = (df_stock[volume_col] / df_stock['Volume_SMA']).fillna(1)\n",
    "\n",
    "    # Momentum indicators\n",
    "    df_stock['MFI'] = ta.volume.MFIIndicator(df_stock[high_col], df_stock[low_col], df_stock[close_col], df_stock[volume_col]).money_flow_index().fillna(50)\n",
    "\n",
    "    # Load scaler\n",
    "    if not os.path.exists(scaler_path):\n",
    "        raise FileNotFoundError(f\"Scaler file {scaler_path} not found.\")\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # Select features and normalize\n",
    "    features = ['Close', 'day_of_week', 'month', 'Returns', 'MACD', 'Signal', 'RSI', 'SMA_20', 'SMA_50', 'EMA_20', 'Volatility', 'ATR', 'Volume_SMA', 'MFI']\n",
    "    target='Close'\n",
    "    # Remove highly correlated features\n",
    "    df_selected = select_features(df_stock[features])\n",
    "\n",
    "    # Drop 'Volume_Ratio' if present (or any other feature that should not be used)\n",
    "    if \"Volume_Ratio\" in df_selected.columns:\n",
    "        df_selected = df_selected.drop(\"Volume_Ratio\", axis=1)\n",
    "\n",
    "    # Select the final set of features after removing unwanted columns\n",
    "    features = [col for col in df_selected.columns if col != [target,'Symbol','Date']]\n",
    "    df_stock[features] = scaler.transform(df_stock[features])\n",
    "\n",
    "    # Prepare sequence for prediction\n",
    "    X = df_stock[features].iloc[-window_size:].values\n",
    "    return np.expand_dims(X, axis=0)  # Shape: (1, window_size, features)\n",
    "\n",
    "def predict_stock_price(model_path, scaler_path, file_path, threshold_percentage=THRESHOLD_PERCENTAGE):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file {model_path} not found.\")\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    X = load_and_preprocess_data(file_path, scaler_path)\n",
    "\n",
    "    # Make prediction (normalized scale)\n",
    "    predicted_price_norm = model.predict(X)[0][0]\n",
    "\n",
    "    # Load scaler and apply inverse transformation\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Only transform the \"Close\" value (we assume it was first in the feature list)\n",
    "    # Get the number of features from the scaler\n",
    "    num_features = scaler.n_features_in_\n",
    "    \n",
    "    # Create an array with the correct shape\n",
    "    input_array = np.zeros((1, num_features))  # Shape (1, num_features)\n",
    "    input_array[0, 0] = predicted_price_norm  # Set only the first column (Close price)\n",
    "    \n",
    "    # Apply inverse transformation\n",
    "    predicted_price_original = scaler.inverse_transform(input_array)[0][0]\n",
    "\n",
    "\n",
    "    # Get last known actual price\n",
    "    df_stock = pd.read_csv(file_path)\n",
    "    actual_price = df_stock['Close'].iloc[-1]  # Assuming 'Close' is the last column\n",
    "\n",
    "    # Calculate threshold region (±2% around predicted price)\n",
    "    lower_bound = predicted_price_original * (1 - threshold_percentage / 100)\n",
    "    upper_bound = predicted_price_original * (1 + threshold_percentage / 100)\n",
    "\n",
    "    # **Enhanced Dynamic Threshold:**\n",
    "    # You can also adjust the threshold region dynamically based on the recent price fluctuation\n",
    "    # For example, you can check the recent percentage change to expand the range.\n",
    "    recent_price_change = (df_stock['Close'].iloc[-1] - df_stock['Close'].iloc[-2]) / df_stock['Close'].iloc[-2] * 100\n",
    "    dynamic_threshold_percentage = threshold_percentage + abs(recent_price_change) / 2  # Adding a factor of recent fluctuation\n",
    "    lower_bound = actual_price * (1 - threshold_percentage / 100)\n",
    "    upper_bound = actual_price * (1 + threshold_percentage / 100)\n",
    "\n",
    "    # Check if actual price is within the threshold region\n",
    "    is_accurate = lower_bound <= predicted_price_original <= upper_bound\n",
    "    accuracy = (actual_price - predicted_price_original) / predicted_price_original * 100  # Accuracy in percentage\n",
    "    if accuracy<0:\n",
    "        accuracy=accuracy*-1\n",
    "\n",
    "    last_date = df_stock['Date'].iloc[-1]  # Get the last date from the 'Date' column\n",
    "    return predicted_price_original, actual_price, is_accurate, accuracy, last_date\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = '../NULB/'  # Update to your actual data path\n",
    "\n",
    "    for file_name in os.listdir(data_directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            stock_name = os.path.splitext(file_name)[0]\n",
    "            file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "            model_path = os.path.join(data_directory, f\"{stock_name}_tft_model.keras\")\n",
    "            scaler_path = os.path.join(data_directory, f\"{stock_name}_scaler.pkl\")\n",
    "\n",
    "            try:\n",
    "                predicted_price, actual_price, is_accurate, accuracy, last_column_date = predict_stock_price(\n",
    "                    model_path, scaler_path, file_path\n",
    "                )\n",
    "\n",
    "                date_obj = datetime.strptime(last_column_date, '%Y-%m-%d')\n",
    "                \n",
    "                # Add one day\n",
    "                new_date_obj = date_obj + timedelta(days=1)\n",
    "                \n",
    "                # Convert back to string if needed\n",
    "                new_date_str = new_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "                print(f\"Predicted price for {stock_name}: {predicted_price:.2f} for date: {new_date_str}\")\n",
    "                print(f\"Actual price: {actual_price:.2f}\")\n",
    "                print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "                print(f\"Threshold region: {predicted_price * (1 - THRESHOLD_PERCENTAGE / 100):.2f} to {predicted_price * (1 + THRESHOLD_PERCENTAGE / 100):.2f}\")\n",
    "                print(f\"Prediction is within threshold: {is_accurate}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {stock_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af9e8f-2aa5-4ec1-beba-fec9104ec477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
